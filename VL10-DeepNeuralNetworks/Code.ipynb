{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeeCarter Neural Network Model\n",
    "In this Jupyter notebook we try to reproduce the Neural Network as given in Ronald & WÃ¼thrich, presented in Lecture 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixkuhn/Library/Python/3.12/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I did not find the data as presented in the lecture, I had to put it together from the hmd-data available. I saved it in the file `mortality_rates.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age limit:  101 Country limit 42 Gender limit 2\n"
     ]
    }
   ],
   "source": [
    "TrainData = pd.read_csv('mortality_rates.csv')\n",
    "YearData = TrainData['Year'].values.reshape(-1, 1)\n",
    "AgeData = TrainData['Age'].values.reshape(-1, 1)\n",
    "_CountryData = TrainData['Country'].values\n",
    "_GenderData = TrainData[\"sex\"].values\n",
    "# Encode country strings to integers\n",
    "CountryData = label_encoder.fit_transform(_CountryData).reshape(-1, 1)\n",
    "GenderData = label_encoder.fit_transform(_GenderData).reshape(-1, 1)\n",
    "\n",
    "ageLim = AgeData.max()+1\n",
    "CountryLim = CountryData.max()+1\n",
    "GenderLim = GenderData.max()+1\n",
    "\n",
    "print(\"Age limit: \", ageLim, \"Country limit\", CountryLim, \"Gender limit\", GenderLim) #I had to modify the code as I seemed to have a country more than the Wuethrich dataset. Gender and age however are the same.\n",
    "\n",
    "TargetData = TrainData['log_mx'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define embedding dimensions\n",
    "age_embedding_dim = 5\n",
    "gender_embedding_dim = 5\n",
    "country_embedding_dim = 5\n",
    "\n",
    "# Define input layers\n",
    "Year = Input(shape=(1,), dtype='float32', name='Year')\n",
    "Age = Input(shape=(1,), dtype='int32', name='Age')\n",
    "Country = Input(shape=(1,), dtype='int32', name='Country')\n",
    "Gender = Input(shape=(1,), dtype='int32', name='Gender')\n",
    "\n",
    "# Define embedding layers\n",
    "Age_embed = Flatten()(Embedding(input_dim=ageLim, output_dim=age_embedding_dim, input_length=1, name='Age_embed')(Age))\n",
    "Gender_embed = Flatten()(Embedding(input_dim=GenderLim, output_dim=gender_embedding_dim, input_length=1, name='Gender_embed')(Gender))\n",
    "Country_embed = Flatten()(Embedding(input_dim=CountryLim, output_dim=country_embedding_dim, input_length=1, name='Country_embed')(Country))\n",
    "\n",
    "# Concatenate features\n",
    "features = Concatenate()([Year, Age_embed, Gender_embed, Country_embed])\n",
    "\n",
    "# Define middle layers\n",
    "middle = features\n",
    "dropout_rate = 0.05\n",
    "for _ in range(4):\n",
    "    middle = Dense(units=128, activation='tanh')(middle)\n",
    "    middle = BatchNormalization()(middle)\n",
    "    middle = Dropout(dropout_rate)(middle)\n",
    "\n",
    "# Define main output\n",
    "main_output = Concatenate()([features, middle])\n",
    "main_output = Dense(units=128, activation='tanh')(main_output)\n",
    "main_output = BatchNormalization()(main_output)\n",
    "main_output = Dropout(dropout_rate)(main_output)\n",
    "main_output = Dense(units=1, activation='sigmoid', name='main_output')(main_output)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[Year, Age, Country, Gender], outputs=[main_output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391274, 1) (391274, 1) (391274, 1) (391274, 1) (391274, 1)\n"
     ]
    }
   ],
   "source": [
    "print(YearData.shape, AgeData.shape, CountryData.shape, GenderData.shape, TargetData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate some test data\n",
    "num_samples = 1000\n",
    "YearData = np.random.randint(2000, 2021, size=(num_samples, 1)).astype('int32')\n",
    "AgeData = np.random.randint(0, 100, size=(num_samples, 1)).astype('int32')\n",
    "CountryData = np.random.randint(0, 41, size=(num_samples, 1)).astype('int32')\n",
    "GenderData = np.random.randint(0, 2, size=(num_samples, 1)).astype('int32')\n",
    "TargetData = np.random.randint(0, 2, size=(num_samples, 1)).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1000, 1) (1000, 1) (1000, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(YearData.shape, AgeData.shape, CountryData.shape, GenderData.shape, TargetData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 29.57295, saving model to Lee_Carter_NN_model.keras\n",
      "\n",
      "Epoch 2: val_loss improved from 29.57295 to 29.57294, saving model to Lee_Carter_NN_model.keras\n",
      "\n",
      "Epoch 3: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 4: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 5: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 6: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 7: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 8: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 9: val_loss did not improve from 29.57294\n",
      "\n",
      "Epoch 10: val_loss did not improve from 29.57294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x377989a00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='mse')#, metrics=['accuracy'])\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(factor=0.80, patience=5, verbose=1, cooldown=5, min_lr=0.00005)\n",
    "\n",
    "mc_callback = ModelCheckpoint(\n",
    "    filepath='Lee_Carter_NN_model.keras',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x=[YearData, AgeData, CountryData, GenderData], \n",
    "          y=TargetData, \n",
    "          epochs=10, \n",
    "          batch_size=32, \n",
    "          verbose=0,\n",
    "          shuffle=True,\n",
    "          validation_split=0.05,\n",
    "          callbacks=[mc_callback, lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
