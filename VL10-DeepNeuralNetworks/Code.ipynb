{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.25644, saving model to Lee_Carter_NN_model.keras\n",
      "\n",
      "Epoch 2: val_loss improved from 0.25644 to 0.25497, saving model to Lee_Carter_NN_model.keras\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.25497\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.25497\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.25497\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.25497\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.25497\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 8: val_loss improved from 0.25497 to 0.25288, saving model to Lee_Carter_NN_model.keras\n",
      "\n",
      "Epoch 9: val_loss improved from 0.25288 to 0.25175, saving model to Lee_Carter_NN_model.keras\n",
      "\n",
      "Epoch 10: val_loss improved from 0.25175 to 0.25087, saving model to Lee_Carter_NN_model.keras\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ccf7563410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Define embedding dimensions\n",
    "age_embedding_dim = 5\n",
    "gender_embedding_dim = 5\n",
    "country_embedding_dim = 5\n",
    "\n",
    "# Define input layers\n",
    "Year = Input(shape=(1,), dtype='float32', name='Year')\n",
    "Age = Input(shape=(1,), dtype='int32', name='Age')\n",
    "Country = Input(shape=(1,), dtype='int32', name='Country')\n",
    "Gender = Input(shape=(1,), dtype='int32', name='Gender')\n",
    "\n",
    "# Define embedding layers\n",
    "Age_embed = Flatten()(Embedding(input_dim=100, output_dim=age_embedding_dim, input_length=1, name='Age_embed')(Age))\n",
    "Gender_embed = Flatten()(Embedding(input_dim=2, output_dim=gender_embedding_dim, input_length=1, name='Gender_embed')(Gender))\n",
    "Country_embed = Flatten()(Embedding(input_dim=41, output_dim=country_embedding_dim, input_length=1, name='Country_embed')(Country))\n",
    "\n",
    "# Concatenate features\n",
    "features = Concatenate()([Year, Age_embed, Gender_embed, Country_embed])\n",
    "\n",
    "# Define middle layers\n",
    "middle = features\n",
    "dropout_rate = 0.05\n",
    "for _ in range(4):\n",
    "    middle = Dense(units=128, activation='tanh')(middle)\n",
    "    middle = BatchNormalization()(middle)\n",
    "    middle = Dropout(dropout_rate)(middle)\n",
    "\n",
    "# Define main output\n",
    "main_output = Concatenate()([features, middle])\n",
    "main_output = Dense(units=128, activation='tanh')(main_output)\n",
    "main_output = BatchNormalization()(main_output)\n",
    "main_output = Dropout(dropout_rate)(main_output)\n",
    "main_output = Dense(units=1, activation='sigmoid', name='main_output')(main_output)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[Year, Age, Country, Gender], outputs=[main_output])\n",
    "# Generate some test data\n",
    "num_samples = 1000\n",
    "Year_data = np.random.randint(2000, 2021, size=(num_samples, 1)).astype('int32')\n",
    "Age_data = np.random.randint(0, 100, size=(num_samples, 1)).astype('int32')\n",
    "Country_data = np.random.randint(0, 41, size=(num_samples, 1)).astype('int32')\n",
    "Gender_data = np.random.randint(0, 2, size=(num_samples, 1)).astype('int32')\n",
    "target_data = np.random.randint(0, 2, size=(num_samples, 1)).astype('float32')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='mse')#, metrics=['accuracy'])\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(factor=0.80, patience=5, verbose=1, cooldown=5, min_lr=0.00005)\n",
    "\n",
    "mc_callback = ModelCheckpoint(\n",
    "    filepath='Lee_Carter_NN_model.keras',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x=[Year_data, Age_data, Country_data, Gender_data], \n",
    "          y=target_data, \n",
    "          epochs=10, \n",
    "          batch_size=32, \n",
    "          verbose=0,\n",
    "          shuffle=True,\n",
    "          validation_split=0.05,\n",
    "          callbacks=[mc_callback, lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
